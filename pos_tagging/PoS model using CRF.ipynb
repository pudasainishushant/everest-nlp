{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = glob.glob(\"pos_data/data_1/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for file in text_files:\n",
    "    with open(file,'r',encoding=\"UTF-8-SIG\") as f:\n",
    "        for line in f.readlines():\n",
    "            sentences.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4291"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(sentence):\n",
    "    tokens = re.split(r\"<\\w+><\\w+>\\s?|<\\w+>\\s?\",sentence)[:-1]\n",
    "    tags = re.findall(r\"<\\w+><\\w+>|<\\w+>\",sentence)\n",
    "    return [tokens,tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = list(map(create_data,sentences))\n",
    "len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The number of tokens and tags has to be of same length.\n",
    "So, checking if we have not equal items in the dataset.\n",
    "If we have unequal item then we take it's index value and store it.\n",
    "\n",
    "Previously, the tokens and tags were not of same length in some senteces.\n",
    "So, I needed to change teh regex pattern for getting the tags and tokens.\n",
    "'''\n",
    "not_equal = []\n",
    "for items in data_set:\n",
    "    if len(items[0]) != len(items[1]):\n",
    "        not_equal.append(data_set.index(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extracting features of the words from a sentence\n",
    "'''\n",
    "def extract_features(sentence,index):\n",
    "    return {\n",
    "        'word':sentence[index],\n",
    "        'is_first':index==0,\n",
    "        'is_last':index ==len(sentence)-1,\n",
    "        'is_alphanumeric': int(bool((re.match('^(?=.*[0-9]$)(?=.*)',sentence[index])))),\n",
    "        'prefix-1':sentence[index][0],\n",
    "        'prefix-2':sentence[index][:2],\n",
    "        'prefix-3':sentence[index][:3],\n",
    "        'prefix-3':sentence[index][:4],\n",
    "        'suffix-1':sentence[index][-1],\n",
    "        'suffix-2':sentence[index][-2:],\n",
    "        'suffix-3':sentence[index][-3:],\n",
    "        'suffix-3':sentence[index][-4:],\n",
    "        'prev_word':'' if index == 0 else sentence[index-1],\n",
    "        'next_word':'' if index < len(sentence) else sentence[index+1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function will use the above extract_features method and give us the feature along with its\n",
    "respective PoS tag\n",
    "'''\n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    "    for sentence,tags in tagged_sentences:\n",
    "        sent_word_features, sent_tags = [],[]\n",
    "        for index in range(len(sentence)):\n",
    "            sent_word_features.append(extract_features(sentence,index))\n",
    "            sent_tags.append(tags[index])\n",
    "        X.append(sent_word_features)\n",
    "        y.append(sent_tags)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training size is:  3432\n",
      "The testing size is:  859\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8*len(data_set))\n",
    "print (\"The training size is: \",train_size)\n",
    "print (\"The testing size is: \",len(data_set)-train_size)\n",
    "\n",
    "train_data = data_set[:train_size]\n",
    "test_data = data_set[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = transform_to_dataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = transform_to_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training the tagger\n",
    "'''\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "model = CRF(\n",
    "    algorithm=\"lbfgs\",\n",
    "    c1=0.01,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite:  11%|█         | 382/3432 [00:00<00:00, 3814.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 3432/3432 [00:00<00:00, 4257.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 60841\n",
      "Seconds required: 0.182\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.010000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=1.17  loss=313124.60 active=60817 feature_norm=1.00\n",
      "Iter 2   time=1.22  loss=286093.73 active=60581 feature_norm=15.72\n",
      "Iter 3   time=0.61  loss=148439.47 active=59328 feature_norm=17.52\n",
      "Iter 4   time=0.62  loss=116877.51 active=59943 feature_norm=16.44\n",
      "Iter 5   time=0.60  loss=102131.69 active=60066 feature_norm=16.55\n",
      "Iter 6   time=0.60  loss=86194.64 active=60255 feature_norm=18.39\n",
      "Iter 7   time=0.61  loss=63172.98 active=60026 feature_norm=23.71\n",
      "Iter 8   time=0.59  loss=51281.11 active=59722 feature_norm=30.61\n",
      "Iter 9   time=0.61  loss=42312.98 active=60332 feature_norm=33.08\n",
      "Iter 10  time=0.62  loss=36728.28 active=60334 feature_norm=37.71\n",
      "Iter 11  time=0.59  loss=33023.08 active=60519 feature_norm=39.89\n",
      "Iter 12  time=0.59  loss=29373.28 active=60447 feature_norm=44.33\n",
      "Iter 13  time=0.59  loss=25472.20 active=60345 feature_norm=50.50\n",
      "Iter 14  time=0.59  loss=22136.14 active=60212 feature_norm=56.77\n",
      "Iter 15  time=0.60  loss=19831.13 active=60059 feature_norm=62.17\n",
      "Iter 16  time=0.61  loss=17872.13 active=60009 feature_norm=67.48\n",
      "Iter 17  time=0.59  loss=16188.94 active=59583 feature_norm=72.55\n",
      "Iter 18  time=0.59  loss=15151.02 active=57713 feature_norm=83.73\n",
      "Iter 19  time=0.59  loss=13434.67 active=57999 feature_norm=86.35\n",
      "Iter 20  time=0.63  loss=12911.43 active=57834 feature_norm=88.58\n",
      "Iter 21  time=0.60  loss=11463.55 active=56037 feature_norm=99.43\n",
      "Iter 22  time=0.61  loss=11148.85 active=55235 feature_norm=105.02\n",
      "Iter 23  time=0.59  loss=10203.33 active=55879 feature_norm=106.37\n",
      "Iter 24  time=0.60  loss=9760.77  active=55520 feature_norm=108.81\n",
      "Iter 25  time=0.59  loss=8938.45  active=54037 feature_norm=116.22\n",
      "Iter 26  time=0.59  loss=8486.13  active=53137 feature_norm=121.79\n",
      "Iter 27  time=0.61  loss=8077.65  active=52849 feature_norm=123.97\n",
      "Iter 28  time=0.59  loss=7864.94  active=52482 feature_norm=125.14\n",
      "Iter 29  time=0.60  loss=7543.66  active=50309 feature_norm=128.67\n",
      "Iter 30  time=0.61  loss=7279.18  active=49530 feature_norm=131.90\n",
      "Iter 31  time=0.59  loss=7003.12  active=48673 feature_norm=136.68\n",
      "Iter 32  time=0.60  loss=6926.55  active=48738 feature_norm=140.07\n",
      "Iter 33  time=0.59  loss=6798.68  active=49092 feature_norm=139.88\n",
      "Iter 34  time=0.60  loss=6752.88  active=48842 feature_norm=140.03\n",
      "Iter 35  time=0.60  loss=6715.15  active=48669 feature_norm=140.37\n",
      "Iter 36  time=0.59  loss=6654.17  active=48544 feature_norm=141.10\n",
      "Iter 37  time=0.60  loss=6653.58  active=47346 feature_norm=144.19\n",
      "Iter 38  time=0.60  loss=6521.77  active=47449 feature_norm=144.44\n",
      "Iter 39  time=0.59  loss=6511.13  active=47418 feature_norm=144.60\n",
      "Iter 40  time=0.59  loss=6440.64  active=46730 feature_norm=146.31\n",
      "Iter 41  time=0.61  loss=6386.79  active=46548 feature_norm=147.50\n",
      "Iter 42  time=0.60  loss=6348.75  active=46319 feature_norm=148.65\n",
      "Iter 43  time=0.60  loss=6319.73  active=46160 feature_norm=149.38\n",
      "Iter 44  time=0.60  loss=6301.45  active=46034 feature_norm=149.75\n",
      "Iter 45  time=0.60  loss=6283.41  active=45756 feature_norm=150.25\n",
      "Iter 46  time=0.61  loss=6270.19  active=45553 feature_norm=150.57\n",
      "Iter 47  time=0.60  loss=6258.78  active=45416 feature_norm=150.76\n",
      "Iter 48  time=0.59  loss=6245.52  active=45141 feature_norm=150.98\n",
      "Iter 49  time=0.60  loss=6238.57  active=44761 feature_norm=151.13\n",
      "Iter 50  time=0.61  loss=6227.76  active=44702 feature_norm=151.20\n",
      "Iter 51  time=0.59  loss=6221.37  active=44503 feature_norm=151.27\n",
      "Iter 52  time=0.59  loss=6210.92  active=44138 feature_norm=151.38\n",
      "Iter 53  time=0.59  loss=6210.72  active=43819 feature_norm=151.49\n",
      "Iter 54  time=0.59  loss=6199.15  active=43776 feature_norm=151.56\n",
      "Iter 55  time=0.59  loss=6194.73  active=43659 feature_norm=151.61\n",
      "Iter 56  time=0.59  loss=6187.12  active=43337 feature_norm=151.73\n",
      "Iter 57  time=0.61  loss=6181.95  active=43173 feature_norm=151.80\n",
      "Iter 58  time=0.60  loss=6177.15  active=43035 feature_norm=151.84\n",
      "Iter 59  time=0.60  loss=6173.01  active=42933 feature_norm=151.95\n",
      "Iter 60  time=0.60  loss=6168.92  active=42823 feature_norm=152.03\n",
      "Iter 61  time=0.63  loss=6165.63  active=42737 feature_norm=152.10\n",
      "Iter 62  time=0.60  loss=6162.80  active=42708 feature_norm=152.16\n",
      "Iter 63  time=0.61  loss=6159.98  active=42643 feature_norm=152.27\n",
      "Iter 64  time=0.64  loss=6157.72  active=42573 feature_norm=152.31\n",
      "Iter 65  time=0.64  loss=6155.32  active=42513 feature_norm=152.39\n",
      "Iter 66  time=0.64  loss=6153.46  active=42503 feature_norm=152.42\n",
      "Iter 67  time=0.65  loss=6151.53  active=42517 feature_norm=152.46\n",
      "Iter 68  time=0.63  loss=6149.82  active=42461 feature_norm=152.47\n",
      "Iter 69  time=0.59  loss=6148.24  active=42433 feature_norm=152.50\n",
      "Iter 70  time=0.61  loss=6146.71  active=42405 feature_norm=152.52\n",
      "Iter 71  time=0.59  loss=6145.26  active=42374 feature_norm=152.54\n",
      "Iter 72  time=0.59  loss=6143.99  active=42355 feature_norm=152.54\n",
      "Iter 73  time=0.60  loss=6142.75  active=42338 feature_norm=152.55\n",
      "Iter 74  time=0.60  loss=6141.62  active=42308 feature_norm=152.55\n",
      "Iter 75  time=0.60  loss=6140.40  active=42276 feature_norm=152.56\n",
      "Iter 76  time=0.60  loss=6139.29  active=42273 feature_norm=152.56\n",
      "Iter 77  time=0.59  loss=6138.25  active=42249 feature_norm=152.55\n",
      "Iter 78  time=0.59  loss=6137.24  active=42225 feature_norm=152.54\n",
      "Iter 79  time=0.59  loss=6136.32  active=42194 feature_norm=152.52\n",
      "Iter 80  time=0.58  loss=6135.29  active=42184 feature_norm=152.50\n",
      "Iter 81  time=0.59  loss=6134.43  active=42167 feature_norm=152.49\n",
      "Iter 82  time=0.59  loss=6133.58  active=42161 feature_norm=152.47\n",
      "Iter 83  time=0.60  loss=6132.85  active=42134 feature_norm=152.45\n",
      "Iter 84  time=0.60  loss=6132.13  active=42121 feature_norm=152.43\n",
      "Iter 85  time=0.59  loss=6131.42  active=42105 feature_norm=152.41\n",
      "Iter 86  time=0.59  loss=6130.71  active=42105 feature_norm=152.39\n",
      "Iter 87  time=0.59  loss=6130.08  active=42100 feature_norm=152.36\n",
      "Iter 88  time=0.58  loss=6129.44  active=42078 feature_norm=152.32\n",
      "Iter 89  time=0.59  loss=6128.84  active=42067 feature_norm=152.29\n",
      "Iter 90  time=0.59  loss=6128.23  active=42062 feature_norm=152.26\n",
      "Iter 91  time=0.58  loss=6127.71  active=42047 feature_norm=152.24\n",
      "Iter 92  time=0.59  loss=6127.19  active=42052 feature_norm=152.21\n",
      "Iter 93  time=0.59  loss=6126.73  active=42039 feature_norm=152.18\n",
      "Iter 94  time=0.59  loss=6126.23  active=42021 feature_norm=152.15\n",
      "Iter 95  time=0.59  loss=6125.78  active=42007 feature_norm=152.13\n",
      "Iter 96  time=0.59  loss=6125.31  active=42012 feature_norm=152.11\n",
      "Iter 97  time=0.59  loss=6124.91  active=41992 feature_norm=152.09\n",
      "Iter 98  time=0.59  loss=6124.50  active=41998 feature_norm=152.07\n",
      "Iter 99  time=0.59  loss=6124.13  active=41985 feature_norm=152.06\n",
      "Iter 100 time=0.59  loss=6123.74  active=41970 feature_norm=152.04\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 61.116\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 41970 (60841)\n",
      "Number of active attributes: 27446 (37558)\n",
      "Number of active labels: 53 (53)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.017\n",
      "\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting to train\")\n",
    "model.fit(X_train,y_train)\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting\n",
    "pred_result = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<CD>',\n",
       " '<NN>',\n",
       " '<POP>',\n",
       " '<FB>',\n",
       " '<NNP>',\n",
       " '<PLE>',\n",
       " '<JJ>',\n",
       " '<CC>',\n",
       " '<VBF>',\n",
       " '<YF>',\n",
       " '<RBO>',\n",
       " '<PKO>',\n",
       " '<YM>',\n",
       " '<PP>',\n",
       " '<VBNE>',\n",
       " '<JJM>',\n",
       " '<VBI>',\n",
       " '<VBKO>',\n",
       " '<VBX>',\n",
       " '<PLAI>',\n",
       " '<DM>',\n",
       " '<PPR>',\n",
       " '<HRU>',\n",
       " '<CS>',\n",
       " '<VBO>',\n",
       " '<YQ>',\n",
       " '<DUM>',\n",
       " '<RP>',\n",
       " '<CL>',\n",
       " '<RBM>',\n",
       " '<JJD>',\n",
       " '<SYM>',\n",
       " '<OD>',\n",
       " '<QW>',\n",
       " '<UNW>',\n",
       " '<HRU><NN>',\n",
       " '<NN><NN>',\n",
       " '<JJ><JJ>',\n",
       " '<VBI><NN>',\n",
       " '<PLE><NN>',\n",
       " '<YB>',\n",
       " '<FW>',\n",
       " '<VBKO><VBKO>',\n",
       " '<CD><CD>',\n",
       " '<YB><VBX>',\n",
       " '<PKO><NNP>',\n",
       " '<POP><NN>',\n",
       " '<YQ><NNP>',\n",
       " '<PLAI><NN>',\n",
       " '<YM><NNP>',\n",
       " '<PP><PP>',\n",
       " '<YF><YF>',\n",
       " '<YF><VBF>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "List of the different PoS tags (classes) that we have\n",
    "'''\n",
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on Test Data\n",
      "0.9523727276652705\n",
      "**************\n",
      "F1 score on Test Data\n",
      "0.9518721361828959\n",
      "**************\n",
      "Precision score on Test Data\n",
      "0.9515483971852243\n",
      "**************\n",
      "Recall score on Test Data\n",
      "0.952742980561555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Aakash/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1465: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/home/user/Aakash/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user/Aakash/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report,flat_f1_score,flat_accuracy_score,flat_recall_score,flat_precision_score\n",
    "\n",
    "print(\"Accuracy score on Test Data\")\n",
    "print(flat_accuracy_score(y_test,pred_result,))\n",
    "print(\"**************\")\n",
    "print(\"F1 score on Test Data\")\n",
    "print(flat_f1_score(y_test,pred_result,average=\"weighted\",labels=model.classes_))\n",
    "print(\"**************\")\n",
    "print(\"Precision score on Test Data\")\n",
    "print(flat_precision_score(y_test,pred_result,average=\"weighted\",labels=model.classes_))\n",
    "print(\"**************\")\n",
    "print(\"Recall score on Test Data\")\n",
    "print(flat_recall_score(y_test,pred_result,average=\"weighted\",labels=model.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Aakash/env/lib/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=['<CD>', '<NN>', '<POP>', '<FB>', '<NNP>', '<PLE>', '<JJ>', '<CC>', '<VBF>', '<YF>', '<RBO>', '<PKO>', '<YM>', '<PP>', '<VBNE>', '<JJM>', '<VBI>', '<VBKO>', '<VBX>', '<PLAI>', '<DM>', '<PPR>', '<HRU>', '<CS>', '<VBO>', '<YQ>', '<DUM>', '<RP>', '<CL>', '<RBM>', '<JJD>', '<SYM>', '<OD>', '<QW>', '<UNW>', '<HRU><NN>', '<NN><NN>', '<JJ><JJ>', '<VBI><NN>', '<PLE><NN>', '<YB>', '<FW>', '<VBKO><VBKO>', '<CD><CD>', '<YB><VBX>', '<PKO><NNP>', '<POP><NN>', '<YQ><NNP>', '<PLAI><NN>', '<YM><NNP>', '<PP><PP>', '<YF><YF>', '<YF><VBF>'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/home/user/Aakash/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/user/Aakash/env/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        <CD>      0.990     0.982     0.986       728\n",
      "        <NN>      0.929     0.960     0.944      5980\n",
      "       <POP>      0.983     0.984     0.984      1510\n",
      "        <FB>      0.944     0.971     0.957        69\n",
      "       <NNP>      0.902     0.876     0.889      1658\n",
      "       <PLE>      0.992     0.999     0.995       701\n",
      "        <JJ>      0.906     0.854     0.879      2014\n",
      "        <CC>      0.995     0.986     0.990       565\n",
      "       <VBF>      0.986     0.964     0.975       786\n",
      "        <YF>      0.999     0.998     0.998       881\n",
      "       <RBO>      0.845     0.855     0.850       433\n",
      "       <PKO>      0.995     0.997     0.996      1566\n",
      "        <YM>      1.000     0.997     0.999       725\n",
      "        <PP>      0.990     0.993     0.991       286\n",
      "      <VBNE>      0.960     0.968     0.964       371\n",
      "       <JJM>      0.904     0.837     0.869       202\n",
      "       <VBI>      0.961     0.948     0.954       386\n",
      "      <VBKO>      0.964     0.995     0.979       558\n",
      "       <VBX>      0.969     0.982     0.975       597\n",
      "      <PLAI>      1.000     0.998     0.999       451\n",
      "        <DM>      0.667     0.880     0.759        25\n",
      "       <PPR>      1.000     0.963     0.981       136\n",
      "       <HRU>      1.000     0.997     0.999       679\n",
      "        <CS>      0.916     0.904     0.910       157\n",
      "       <VBO>      0.884     0.901     0.892       373\n",
      "        <YQ>      1.000     1.000     1.000       373\n",
      "       <DUM>      0.976     0.972     0.974       458\n",
      "        <RP>      0.993     0.985     0.989       137\n",
      "        <CL>      1.000     1.000     1.000        85\n",
      "       <RBM>      0.333     0.095     0.148        21\n",
      "       <JJD>      0.971     0.846     0.904        39\n",
      "       <SYM>      0.993     1.000     0.996       135\n",
      "        <OD>      0.568     0.724     0.636        29\n",
      "        <QW>      0.952     0.909     0.930        22\n",
      "       <UNW>      0.000     0.000     0.000         0\n",
      "   <HRU><NN>      0.000     0.000     0.000         0\n",
      "    <NN><NN>      0.000     0.000     0.000         4\n",
      "    <JJ><JJ>      0.000     0.000     0.000         0\n",
      "   <VBI><NN>      0.000     0.000     0.000         0\n",
      "   <PLE><NN>      0.000     0.000     0.000         0\n",
      "        <YB>      0.000     0.000     0.000         2\n",
      "        <FW>      0.000     0.000     0.000         8\n",
      "<VBKO><VBKO>      0.000     0.000     0.000         0\n",
      "    <CD><CD>      0.000     0.000     0.000         0\n",
      "   <YB><VBX>      0.000     0.000     0.000         0\n",
      "  <PKO><NNP>      0.000     0.000     0.000         0\n",
      "   <POP><NN>      0.000     0.000     0.000         0\n",
      "   <YQ><NNP>      0.000     0.000     0.000         0\n",
      "  <PLAI><NN>      0.000     0.000     0.000         0\n",
      "   <YM><NNP>      0.000     0.000     0.000         0\n",
      "    <PP><PP>      0.000     0.000     0.000         0\n",
      "    <YF><YF>      0.000     0.000     0.000         0\n",
      "   <YF><VBF>      0.000     0.000     0.000         0\n",
      "\n",
      "   micro avg      0.952     0.953     0.953     23150\n",
      "   macro avg      0.594     0.591     0.590     23150\n",
      "weighted avg      0.952     0.953     0.952     23150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(flat_classification_report(y_test,pred_result,labels=model.classes_,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "म \t <PP>\n",
      "आजा \t <NN>\n",
      "भात \t <NN>\n",
      "खान्छु \t <VBF>\n",
      ", \t <YM>\n",
      "अनि \t <CC>\n",
      "बल्ल \t <NN>\n",
      "खेल्न \t <VBI>\n",
      "जान्छु \t <VBF>\n",
      "। \t <YF>\n"
     ]
    }
   ],
   "source": [
    "text = \"म आजा भात खान्छु , अनि बल्ल खेल्न जान्छु ।\"\n",
    "\n",
    "tokens = text.split(\" \")\n",
    "features = [extract_features(tokens,index) for index in range(len(tokens))]\n",
    "\n",
    "result = model.predict_single(features)\n",
    "# print(result)\n",
    "for i in range(len(tokens)):\n",
    "    print(tokens[i],\"\\t\", result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_name = \"./pos_model/pos_tag_crf.sav\"\n",
    "pickle.dump(model,open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model = pickle.load(open(file_name,'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
